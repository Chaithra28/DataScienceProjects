{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "3eb319b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "2df58630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"1676558209_8416622_cleveland-train.csv\")\n",
    "train_data['heartdisease::category|-1|1'].replace({1:1, -1:0}, inplace = True)\n",
    "\n",
    "X_train = train_data.drop('heartdisease::category|-1|1', axis = 1).to_numpy()\n",
    "Y_train = train_data['heartdisease::category|-1|1'].values\n",
    "\n",
    "# Add an intercept column to X\n",
    "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "\n",
    "# Finding mean and standard deviation\n",
    "X_mean = np.mean(X_train, axis=0)\n",
    "X_std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "936a356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def calculate_cost(X, y, weight):\n",
    "    n_train_examples = len(y)\n",
    "    z = np.dot(X, weight)\n",
    "    h = sigmoid(z)\n",
    "    cost = (-1/n_train_examples) * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "    return cost\n",
    "\n",
    "def calculate_gradient(X, y, weight):\n",
    "    n_train_examples = len(y)\n",
    "    z = np.dot(X, weight)\n",
    "    h = sigmoid(z)\n",
    "    gradient = (1/n_train_examples) * np.dot(X.T, (h-y))\n",
    "    return gradient\n",
    "\n",
    "def logistic_regression(X, y, X_mean, X_std, eta=1e-5, tol=1e-3, max_iter=10000):\n",
    "    \n",
    "    # Scaling the X_train data using Normalization\n",
    "    X[:,1:] = (X[:,1:] - X_mean[1:]) / X_std[1:]\n",
    "\n",
    "    # Initialize the weight vector\n",
    "    w = np.zeros(X.shape[1])\n",
    "\n",
    "    # Initialize the cost and gradient\n",
    "    cost = calculate_cost(X, y, w)\n",
    "    grad_mag = np.linalg.norm(calculate_gradient(X, y, w))\n",
    "\n",
    "    iteration = 0\n",
    "    while grad_mag >= tol and iteration < max_iter:\n",
    "        # Compute the gradient and update the weight vector\n",
    "        gradient = calculate_gradient(X, y, w)\n",
    "        w -= eta * gradient\n",
    "\n",
    "        # Compute the new cost and gradient magnitude\n",
    "        new_cost = calculate_cost(X, y, w)\n",
    "        grad_mag = np.linalg.norm(gradient)\n",
    "\n",
    "        # Check if the magnitude of each term in the gradient is below the tolerance\n",
    "        if grad_mag < tol:\n",
    "            break\n",
    "\n",
    "        # Update the iteration counter and cost\n",
    "        iteration += 1\n",
    "        cost = new_cost\n",
    "\n",
    "    # Compute the final classification error on the training set\n",
    "    h = sigmoid(np.dot(X, w))\n",
    "    y_pred = np.round(h)\n",
    "    class_error = np.mean(y_pred != y)\n",
    "\n",
    "    return w, cost, class_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "817d1476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: 53.95 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "weight, cost, class_error = logistic_regression(X_train, Y_train, X_mean, X_std, eta=1e-5, tol=1e-3, max_iter=1000000)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken to train the model: {:.2f} seconds\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "ddac5150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4bf5af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"1676558209_8421676_cleveland-test.csv\")\n",
    "X_test = test_data.to_numpy()\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fa460427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, w):\n",
    "    # Add an intercept column to X_test\n",
    "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "    X_test[:,1:] = (X_test[:,1:] - X_mean[1:]) / X_std[1:]\n",
    "\n",
    "    # Compute the predicted probabilities\n",
    "    h = sigmoid(np.dot(X_test, w))\n",
    "\n",
    "    # Round the probabilities to obtain binary predictions\n",
    "    y_pred = np.round(h)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8395df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, weight).astype(int)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fcadb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "..  ..\n",
      "140  0\n",
      "141  1\n",
      "142  1\n",
      "143  1\n",
      "144  0\n",
      "\n",
      "[145 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(y_pred)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e9f63af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.replace({1:1, 0:-1})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c23df563",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('submission2.csv', index=False, header=False, escapechar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9f94bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: 0.01 seconds\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression using Sklearn Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid=train_test_split(train_data, test_size=0.10, random_state=0)\n",
    "\n",
    "X_train = train.drop('heartdisease::category|-1|1', axis = 1)\n",
    "y_train = train['heartdisease::category|-1|1']\n",
    "X_val = valid.drop('heartdisease::category|-1|1', axis = 1)\n",
    "y_val = valid['heartdisease::category|-1|1']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "start_time = time.time()\n",
    "# Train logistic regression model\n",
    "clf = LogisticRegression(dual=False, max_iter=1000000, C=1, penalty='l2')\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken to train the model: {:.2f} seconds\".format(time_taken))\n",
    "\n",
    "# Predict classes\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Compute accuracy and log loss\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "aa410624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_data)\n",
    "output_library = pd.DataFrame(pred)\n",
    "output_library = output_library.replace({1:1, 0:-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0ada3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "da75fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_library.to_csv('submission3.csv', index=False, header=False, escapechar=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
